# ai-ml-task1-titanic-preprocessing
“Data preprocessing project using the Titanic dataset – part of AI &amp; ML internship. Includes handling nulls, encoding, scaling, and outlier treatment using Python libraries.”
# Task 1: Data Cleaning & Preprocessing – Titanic Dataset

This repository contains my submission for *Task 1* of the AI & ML Internship. The goal of this task is to clean and preprocess the Titanic dataset to make it suitable for Machine Learning.

---

## 📌 Objective

> Learn how to clean and prepare raw data for ML using Python.

---

## 🛠 Tools & Libraries Used

- Python
- Pandas
- NumPy
- Seaborn
- Matplotlib
- Scikit-learn

---

## 🔧 Steps Performed

1. *Imported the dataset* and explored basic information (data types, null values).
2. *Handled missing values* using median (for Age) and mode (for Embarked).
3. *Dropped columns* like Cabin with too many missing values.
4. *Encoded categorical variables* using Label Encoding and One-Hot Encoding.
5. *Visualized outliers* using boxplots (for Fare).
6. *Removed outliers* using the IQR method.
7. *Normalized and Standardized* numerical features using MinMaxScaler and StandardScaler.

---

## 📁 Files Included

| File | Description |
|------|-------------|
| task1_titanic_preprocessing.ipynb | Jupyter Notebook with all code and explanations |
| Titanic-Dataset.csv | Cleaned dataset used for preprocessing |


---

---

## 🧠 What I Learned

- How to handle missing data using different strategies
- The importance of encoding categorical variables
- Detecting and removing outliers effectively
- How scaling impacts model performance

---

## 🚀 How to Run This Notebook

1. Clone the repo or download the ZIP
2. Open the notebook with Jupyter Notebook or Google Colab
3. Run the cells in order to reproduce the results

---

> 🔖 *Task completed as part of AI & ML Internship – proudly submitted by Shivain *
